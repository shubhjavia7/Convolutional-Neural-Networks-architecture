{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SxgKOcBPls0d"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(torch.nn.Module):\n",
        "\n",
        "  class block(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride):\n",
        "      super().__init__()\n",
        "      kernel_size = 3\n",
        "      padding = (kernel_size-1)//2\n",
        "      self.block_model = torch.nn.Sequential( # model\n",
        "          torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding), # only stride the first layer of the block.\n",
        "          torch.nn.BatchNorm2d(out_channels), # normalization. We normalize in between Conv and Relu to deal with bias issues.If we apply before Conv we will have to mess with bias.\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.Conv2d(out_channels, out_channels, kernel_size, 1, padding),\n",
        "          torch.nn.BatchNorm2d(out_channels),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.Conv2d(out_channels, out_channels, kernel_size, 1, padding),\n",
        "          torch.nn.BatchNorm2d(out_channels),\n",
        "          torch.nn.ReLU(),\n",
        "      )\n",
        "\n",
        "      if in_channels != out_channels: # Residual Connections\n",
        "        self.skip = torch.nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=2)\n",
        "      else:\n",
        "        self.skip = torch.nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "      return self.block_model(x) + self.skip(x)\n",
        "\n",
        "\n",
        "  def __init__(self, channels_l0 = 64, n_blocks = 3):\n",
        "    super().__init__()\n",
        "    cnn_layers = [\n",
        "        torch.nn.Conv2d(in_channels=3, out_channels=channels_l0, kernel_size=11, stride=2, padding = (11-1)//2), # blow up the first layer of the network to maintain gradients and create deep networks.\n",
        "        torch.nn.ReLU(),\n",
        "    ]\n",
        "    c1 = channels_l0 # input channels\n",
        "    for _ in range(n_blocks):\n",
        "      c2 = c1*2\n",
        "      cnn_layers.append(self.block(c1,c2,stride =2))\n",
        "      c1 = c2\n",
        "    cnn_layers.append(torch.nn.Conv2d(c1,1,kernel_size=1)) # one cross on conv. classifier layer.\n",
        "    #cnn_layers.append(torch.nn.AdaptiveAvgPool2d(1)) # this will average all outouts. and used for one single classification. if you want to keep all outputs you can not add this line.\n",
        "    self.model = torch.nn.Sequential(*cnn_layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "x = torch.randn(1,3,64,64)\n",
        "net = ConvNet()\n",
        "print(net(x).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKUR-VwXlx25",
        "outputId": "9ced797c-083c-43aa-ac6a-756e29e5f0d4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 4, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAtZOpyyl4D6",
        "outputId": "b66b88ac-00f3-45a0-d3fb-7027d6dedf2b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvNet(\n",
            "  (model): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(2, 2), padding=(5, 5))\n",
            "    (1): ReLU()\n",
            "    (2): block(\n",
            "      (block_model): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      )\n",
            "      (skip): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
            "    )\n",
            "    (3): block(\n",
            "      (block_model): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      )\n",
            "      (skip): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
            "    )\n",
            "    (4): block(\n",
            "      (block_model): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      )\n",
            "      (skip): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
            "    )\n",
            "    (5): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    }
  ]
}